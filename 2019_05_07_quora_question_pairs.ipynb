{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quora Question Pairs\n",
    "This is a personal try at the 2017 Quora Question Pairs Kaggle Competition (https://www.kaggle.com/c/quora-question-pairs/overview).\n",
    "\n",
    "At the heart of this problem is trying to tackle similarity between two questions; the task is to identify if these questions are duplicates, or in other words, are semantially equivalent questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Sizes:\n",
      "test.csv 299.47MB 2345806 lines\n",
      "train.csv 60.46MB 404302 lines\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"File Sizes:\")\n",
    "file_size = os.path.getsize('./test.csv')\n",
    "num_lines = sum(1 for line in open('./test.csv'))\n",
    "print(\"test.csv \" + str(round(file_size / (1024*1024),2)) + \"MB \" + str(num_lines) + \" lines\")\n",
    "file_size = os.path.getsize('./train.csv')\n",
    "num_lines = sum(1 for line in open('./train.csv'))\n",
    "print(\"train.csv \" + str(round(file_size / (1024*1024),2)) + \"MB \" + str(num_lines) + \" lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the test data is significantly larger than the training data and has 6X the number of items than the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "train = pandas.read_csv('./train.csv', dtype={'question1': numpy.unicode_, 'question2': numpy.unicode_})\n",
    "#train.head()\n",
    "train.question1 = train.question1.astype(str)\n",
    "train.question2 = train.question2.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404290\n"
     ]
    }
   ],
   "source": [
    "print(len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does the length of this data frame differ from the line count of the file? Opening up the training file, it looks like some of the question text has incorporated a newline character that splits a single example into multi-lines, but seems like this happens pretty infrequently. As an aside, this file uses carriage returns, so one might reasonably assume this was encoded on Windows. The first example I see for this is on train.csv:line 2334, example id 2332. Just to verify..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.iloc[2332]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this was parsed into the frame properly, so no worries.\n",
    "\n",
    "Next thing we might want to do is look at the occurance of question duplication in the training set. We can do this simply by taking the average of duplicate occurances in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of question pairs that are duplicates: 0.369197853026293\n"
     ]
    }
   ],
   "source": [
    "avg_duplicate_likelihood = train['is_duplicate'].mean()\n",
    "print(\"Fraction of question pairs that are duplicates: \" + str(avg_duplicate_likelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pandas.read_csv('./test.csv', dtype={'question1': numpy.unicode_, 'question2': numpy.unicode_})\n",
    "test.question1 = test.question1.astype(str)\n",
    "test.question2 = test.question2.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that duplicates occur about 36.9% of the time. As a baseline, we could simply predict that all examples have a 36.9% probability of being a duplicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pandas.DataFrame({'test_id': test['test_id'], 'is_duplicate': avg_duplicate_likelihood})\n",
    "sub.to_csv('baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives a 0.554 public score. Let's see how we could do better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation\n",
    "Let's start with a boosting model, creating a number of features. We could consider the proportion of shared words between sentences, shared n-grams, a td-idf weighted share, cosine_similarity (based on word2vec), and levenshtein distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "def word_match_share(row):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in str(row['question1']).translate(str.maketrans('', '', string.punctuation)).lower().split():\n",
    "        if word not in stops:\n",
    "            q1words[word] = 1\n",
    "    for word in str(row['question2']).translate(str.maketrans('', '', string.punctuation)).lower().split():\n",
    "        if word not in stops:\n",
    "            q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n",
    "    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n",
    "    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word sharing as a feature alone provides a public score of 0.42, which is a marked improvement over our baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def bigram_match_share(row):\n",
    "    q1bigram = {}\n",
    "    q2bigram = {}\n",
    "    tokens = [token for token in str(row['question1']).translate(str.maketrans('', '', string.punctuation)).lower().split(\" \") if token != \"\" and token not in stops]\n",
    "    output = list(ngrams(tokens, 2))\n",
    "    for bigram in output:\n",
    "        q1bigram[bigram] = 1\n",
    "    tokens = [token for token in str(row['question2']).translate(str.maketrans('', '', string.punctuation)).lower().split(\" \") if token != \"\" and token not in stops]\n",
    "    output = list(ngrams(tokens, 2))\n",
    "    for bigram in output:\n",
    "        q2bigram[bigram] = 1\n",
    "    if len(q1bigram) == 0 or len(q2bigram) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    shared_bigram_in_q1 = [w for w in q1bigram.keys() if w in q2bigram]\n",
    "    shared_bigram_in_q2 = [w for w in q2bigram.keys() if w in q1bigram]\n",
    "    R = (len(shared_bigram_in_q1) + len(shared_bigram_in_q2))/(len(q1bigram) + len(q2bigram))\n",
    "    return R\n",
    "\n",
    "#bigram_match_share(train.iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def trigram_match_share(row):\n",
    "    q1ngram = {}\n",
    "    q2ngram = {}\n",
    "    tokens = [token for token in str(row['question1']).translate(str.maketrans('', '', string.punctuation)).lower().split(\" \") if token != \"\" and token not in stops]\n",
    "    output = list(ngrams(tokens, 3))\n",
    "    for ngram in output:\n",
    "        q1ngram[ngram] = 1\n",
    "    tokens = [token for token in str(row['question2']).translate(str.maketrans('', '', string.punctuation)).lower().split(\" \") if token != \"\" and token not in stops]\n",
    "    output = list(ngrams(tokens, 3))\n",
    "    for ngram in output:\n",
    "        q2ngram[ngram] = 1\n",
    "    if len(q1ngram) == 0 or len(q2ngram) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    shared_ngram_in_q1 = [w for w in q1ngram.keys() if w in q2ngram]\n",
    "    shared_ngram_in_q2 = [w for w in q2ngram.keys() if w in q1ngram]\n",
    "    R = (len(shared_ngram_in_q1) + len(shared_ngram_in_q2))/(len(q1ngram) + len(q2ngram))\n",
    "    return R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effect of adding a bi-gram and tri-gram feature provided some marginal, ~0.01 improvement on our public score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# If a word appears only once, we ignore it completely (likely a typo)\n",
    "# Epsilon defines a smoothing constant, which makes the effect of extremely rare words smaller\n",
    "def get_weight(count, eps=10000, min_count=2):\n",
    "    if count < min_count:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 / (count + eps)\n",
    "\n",
    "eps = 5000 \n",
    "train_qs = pandas.Series(train['question1'].tolist() + train['question2'].tolist()).astype(str)\n",
    "words = (\" \".join(train_qs)).lower().split()\n",
    "counts = Counter(words)\n",
    "weights = {word: get_weight(count) for word, count in counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_word_match_share(row):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in str(row['question1']).translate(str.maketrans('', '', string.punctuation)).lower().split():\n",
    "        if word not in stops:\n",
    "            q1words[word] = 1\n",
    "    for word in str(row['question2']).translate(str.maketrans('', '', string.punctuation)).lower().split():\n",
    "        if word not in stops:\n",
    "            q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    \n",
    "    shared_weights = [weights.get(w, 0) for w in q1words.keys() if w in q2words] + [weights.get(w, 0) for w in q2words.keys() if w in q1words]\n",
    "    total_weights = [weights.get(w, 0) for w in q1words] + [weights.get(w, 0) for w in q2words]\n",
    "    \n",
    "    R = numpy.sum(shared_weights) / numpy.sum(total_weights)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The td-idf feature provided a marginal decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevinguo/anaconda3/lib/python3.7/site-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
     ]
    }
   ],
   "source": [
    "import pyemd\n",
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_cosine_similarity(row):\n",
    "    q1words = []\n",
    "    q2words = []\n",
    "    for word in str(row['question1']).translate(str.maketrans('', '', string.punctuation)).lower().split():\n",
    "        if word not in stops and word in model.vocab:\n",
    "            q1words.append(word)\n",
    "    for word in str(row['question2']).translate(str.maketrans('', '', string.punctuation)).lower().split():\n",
    "        if word not in stops and word in model.vocab:\n",
    "            q2words.append(word)\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    sim = model.n_similarity(q1words, q2words)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word2vec cosine similarities did not improve the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = pandas.DataFrame()\n",
    "# x_train['word_match'] = train.apply(word_match_share, axis=1, raw=True)\n",
    "# #x_train['tfidf_word_match'] = train.apply(tfidf_word_match_share, axis=1, raw=True)\n",
    "# x_train['word2vec_cosine_similarity'] = train.apply(word2vec_cosine_similarity, axis=1, raw=True)\n",
    "# x_train['q1len'] = train['question1'].str.len()\n",
    "# x_train['q1len'][numpy.isnan(x_train['q1len'])] = 0\n",
    "# x_train['q2len'] = train['question2'].str.len()\n",
    "# x_train['q2len'][numpy.isnan(x_train['q2len'])] = 0\n",
    "# x_train['len_diff'] = abs(x_train['q1len']-x_train['q2len'])\n",
    "# x_train['q1_n_words'] = train['question1'].apply(lambda row: len(str(row).split(\" \")))\n",
    "# x_train['q2_n_words'] = train['question2'].apply(lambda row: len(str(row).split(\" \")))\n",
    "# x_train['q1_num_caps'] = train['question1'].apply(lambda row: sum(1 for c in str(row) if c.isupper()))\n",
    "# x_train['q2_num_caps'] = train['question2'].apply(lambda row: sum(1 for c in str(row) if c.isupper()))\n",
    "\n",
    "# y_train = pandas.DataFrame()\n",
    "# y_train = train['is_duplicate'].values\n",
    "\n",
    "# x_test = pandas.DataFrame()\n",
    "# x_test['word_match'] = test.apply(word_match_share, axis=1, raw=True)\n",
    "# #x_test['tfidf_word_match'] = test.apply(tfidf_word_match_share, axis=1, raw=True)\n",
    "# x_test['word2vec_cosine_similarity'] = test.apply(word2vec_cosine_similarity, axis=1, raw=True)\n",
    "# x_test['q1len'] = test['question1'].str.len()\n",
    "# x_test['q1len'][numpy.isnan(x_test['q1len'])] = 0\n",
    "# x_test['q2len'] = test['question2'].str.len()\n",
    "# x_test['q2len'][numpy.isnan(x_test['q2len'])] = 0\n",
    "# x_test['len_diff'] = abs(x_test['q1len']-x_test['q2len'])\n",
    "# x_test['q1_n_words'] = test['question1'].apply(lambda row: len(str(row).split(\" \")))\n",
    "# x_test['q2_n_words'] = test['question2'].apply(lambda row: len(str(row).split(\" \")))\n",
    "# x_test['q1_num_caps'] = test['question1'].apply(lambda row: sum(1 for c in str(row) if c.isupper()))\n",
    "# x_test['q2_num_caps'] = test['question2'].apply(lambda row: sum(1 for c in str(row) if c.isupper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fuzzywuzzy import fuzz\n",
    "# def lev_dist(row):\n",
    "#     lev_dist = fuzz.ratio(str(row['question1']), str(row['question2']))\n",
    "#     return lev_dist/100\n",
    "# x_train['lev_dist'] = train.apply(lev_dist, axis=1, raw=True)\n",
    "# x_test['lev_dist'] = test.apply(lev_dist, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levenshtein distance provided a mild increase to the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train['bigram_word_match'] = train.apply(bigram_match_share, axis=1, raw=True)\n",
    "# x_test['bigram_word_match'] = test.apply(bigram_match_share, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train['trigram_word_match'] = train.apply(trigram_match_share, axis=1, raw=True)\n",
    "# x_test['trigram_word_match'] = test.apply(trigram_match_share, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_train = x_train[y_train == 1]\n",
    "# neg_train = x_train[y_train == 0]\n",
    "\n",
    "# # Now we oversample the negative class\n",
    "# # There is likely a much more elegant way to do this...\n",
    "# p = 0.165\n",
    "# scale = ((len(pos_train) / (len(pos_train) + len(neg_train))) / p) - 1\n",
    "# while scale > 1:\n",
    "#     neg_train = pandas.concat([neg_train, neg_train])\n",
    "#     scale -=1\n",
    "# neg_train = pandas.concat([neg_train, neg_train[:int(scale * len(neg_train))]])\n",
    "# print(len(pos_train) / (len(pos_train) + len(neg_train)))\n",
    "\n",
    "# x_train = pandas.concat([pos_train, neg_train])\n",
    "# y_train = (numpy.zeros(len(pos_train)) + 1).tolist() + numpy.zeros(len(neg_train)).tolist()\n",
    "# del pos_train, neg_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another kernal suggested to smooth the data and better proportion the positive and negative training examples. Doing this significantly improved the model score, by 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "#print(x_train)\n",
    "#x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "A simple random forest classifier was attempted, but the performance was significantly worse than the boosting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_model = ensemble.RandomForestClassifier()\n",
    "# #print(x_train.values)\n",
    "# #numpy.isnan(y_train)\n",
    "\n",
    "# rf_model.fit(x_train.fillna(0), y_train)\n",
    "# predictions = rf_model.predict(x_valid.fillna(0))\n",
    "# from sklearn import metrics\n",
    "# print(metrics.accuracy_score(predictions, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = rf_model.predict_proba(x_test.fillna(0))\n",
    "# print(predictions[:,1])\n",
    "# sub = pandas.DataFrame({'test_id': test['test_id'], 'is_duplicate': predictions[:,1]})\n",
    "# sub.to_csv('random_forest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model\n",
    "A popular boosting model based on weak learners as opposed to random forest. Saw some of the best performance from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "\n",
    "# # Set our parameters for xgboost\n",
    "# params = {}\n",
    "# params['objective'] = 'binary:logistic'\n",
    "# params['eval_metric'] = 'logloss'\n",
    "# params['eta'] = 0.02\n",
    "# params['max_depth'] = 8\n",
    "\n",
    "# d_train = xgb.DMatrix(x_train, label=y_train)\n",
    "# d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
    "\n",
    "# watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "# bst = xgb.train(params, d_train, 500, watchlist, early_stopping_rounds=50, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_test = xgb.DMatrix(x_test)\n",
    "# p_test = bst.predict(d_test)\n",
    "\n",
    "# sub = pandas.DataFrame()\n",
    "# sub['test_id'] = test['test_id']\n",
    "# sub['is_duplicate'] = p_test\n",
    "# sub.to_csv('simple_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "After attempting numerous iterations and feature engineering with the above boosting model, I attempted using a variety of NN architectures via Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "# input_dim = x_train.shape[1]  # Number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Neural Network\n",
    "The first attempt at a NN via a simple shallow network w/ the existing feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(layers.Dense(100, input_dim=input_dim, activation='relu'))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "# history = model.fit(x_train, y_train, epochs=100, verbose=True, validation_data=(x_valid, y_valid), batch_size=100)\n",
    "# loss, accuracy = model.evaluate(x_train, y_train, verbose=True)\n",
    "# print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "# loss, accuracy = model.evaluate(x_valid, y_valid, verbose=True)\n",
    "# print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model.predict_proba(x_test)\n",
    "# print(predictions[:,0])\n",
    "# sub = pandas.DataFrame({'test_id': test['test_id'], 'is_duplicate': predictions[:,0]})\n",
    "# sub.to_csv('shallow_nn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was the first attempt at using Keras and yielded similar results to the previous boosting approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks and Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "questions = train['question1'] + train['question1']\n",
    "tokenizer = Tokenizer(num_words=200000)\n",
    "tokenizer.fit_on_texts(numpy.append(train['question1'],train['question2']))\n",
    "\n",
    "question1_word_sequences = tokenizer.texts_to_sequences(train['question1'])\n",
    "question2_word_sequences = tokenizer.texts_to_sequences(train['question2'])\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "q1_tokenized = pad_sequences(question1_word_sequences, maxlen=25)\n",
    "q2_tokenized = pad_sequences(question2_word_sequences, maxlen=25)\n",
    "#x_test['question1'] = pad_sequences(x_test['question1'], padding='post', maxlen=maxlen)\n",
    "#x_test['question2'] = pad_sequences(x_test['question2'], padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1_word_sequences_test = tokenizer.texts_to_sequences(test['question1'])\n",
    "question2_word_sequences_test = tokenizer.texts_to_sequences(test['question2'])\n",
    "q1_tokenized_test = pad_sequences(question1_word_sequences_test, maxlen=25)\n",
    "q2_tokenized_test = pad_sequences(question2_word_sequences_test, maxlen=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of question1 data tensor:', q1_tokenized.shape)\n",
    "print('Shape of question2 data tensor:', q2_tokenized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numpy.stack((q1_tokenized, q2_tokenized), axis=1)\n",
    "\n",
    "y_train = pandas.DataFrame()\n",
    "y_train = train['is_duplicate'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y_train, test_size=0.1)\n",
    "q1_train = x_train[:,0]\n",
    "q2_train = x_train[:,1]\n",
    "q1_test = x_test[:,0]\n",
    "q2_test = x_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = numpy.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    embeddings_index = {}\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            values = line.split(' ')\n",
    "            word = values[0]\n",
    "            embedding = numpy.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = embedding\n",
    "\n",
    "    print('Word embeddings: %d' % len(embeddings_index))\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "embedding_matrix = create_embedding_matrix('./glove.840B.300d.txt',tokenizer.word_index, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Null word embeddings: %d' % numpy.sum(numpy.sum(embedding_matrix, axis=1) == 0))\n",
    "nonzero_elements = numpy.count_nonzero(numpy.count_nonzero(embedding_matrix, axis=1))\n",
    "nonzero_elements / vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras import backend as K\n",
    "# from keras.layers import Input, LSTM, Dense, Dropout, TimeDistributed, Lambda, BatchNormalization\n",
    "# from keras.models import Model\n",
    "\n",
    "# question_1 = Input(shape=(25,))\n",
    "# question_2 = Input(shape=(25,))\n",
    "# #word_match = Input(shape=(1,))\n",
    "\n",
    "# # Add the word embedding Layer\n",
    "# embedding_layer_1 = layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False)(question_1)\n",
    "# #embedding_layer_1 = layers.SpatialDropout1D(0.3)(embedding_layer_1)\n",
    "# embedding_layer_1 = TimeDistributed(Dense(embedding_dim, activation='relu'))(embedding_layer_1)\n",
    "# embedding_layer_1 = Lambda(lambda x: K.max(x, axis=1), output_shape=(embedding_dim, ))(embedding_layer_1)\n",
    "\n",
    "# embedding_layer_2 = layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False)(question_2)\n",
    "# #embedding_layer_2 = layers.SpatialDropout1D(0.3)(embedding_layer_2)\n",
    "# embedding_layer_2 = TimeDistributed(Dense(embedding_dim, activation='relu'))(embedding_layer_2)\n",
    "# embedding_layer_2 = Lambda(lambda x: K.max(x, axis=1), output_shape=(embedding_dim, ))(embedding_layer_2)\n",
    "\n",
    "# merged_embedding_vector = keras.layers.concatenate([embedding_layer_1, embedding_layer_2], axis=-1)\n",
    "\n",
    "# # Add the LSTM Layer\n",
    "# #lstm_layer = layers.LSTM(512)\n",
    "\n",
    "# #encoded_q1 = lstm_layer(embedding_layer_1)\n",
    "# #encoded_q2 = lstm_layer(embedding_layer_2)\n",
    "\n",
    "# #merged_embedding_vector = keras.layers.concatenate([encoded_q1, encoded_q2], axis=-1)\n",
    "# #merged_vector = keras.layers.concatenate([encoded_q1, encoded_q2], axis=-1)\n",
    "# #merged_vector = keras.layers.concatenate([merged_embedding_vector, word_match], axis=-1)\n",
    "\n",
    "# # Add the output Layers\n",
    "# merged_vector = layers.Dense(200, activation=\"relu\")(merged_embedding_vector)\n",
    "# merged_vector = Dropout(0.1)(merged_vector)\n",
    "# merged_vector = BatchNormalization()(merged_vector)\n",
    "# merged_vector = layers.Dense(200, activation=\"relu\")(merged_vector)\n",
    "# merged_vector = Dropout(0.1)(merged_vector)\n",
    "# merged_vector = BatchNormalization()(merged_vector)\n",
    "# merged_vector = layers.Dense(200, activation=\"relu\")(merged_vector)\n",
    "# merged_vector = Dropout(0.1)(merged_vector)\n",
    "# merged_vector = BatchNormalization()(merged_vector)\n",
    "# merged_vector = layers.Dense(200, activation=\"relu\")(merged_vector)\n",
    "# merged_vector = Dropout(0.1)(merged_vector)\n",
    "# merged_vector = BatchNormalization()(merged_vector)\n",
    "# #output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "\n",
    "# output_layer2 = layers.Dense(1, activation=\"sigmoid\")(merged_vector)\n",
    "\n",
    "# # Compile the model\n",
    "# #model = Model(inputs=[question_1,question_2,word_match], outputs=output_layer2)\n",
    "# model = Model(inputs=[question_1,question_2], outputs=output_layer2)\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_train['question1'].shape)\n",
    "# print(x_train['question2'].shape)\n",
    "# # print(x_train['word_match'].shape)\n",
    "# q_1 = x_train['question1'].values\n",
    "# q_2 = x_train['question2'].values\n",
    "\n",
    "\n",
    "#input_list = [q_1, q_2, x_train['word_match'].values]\n",
    "#validation_list = [x_test['question1'].values, x_test['question2'].values, x_test['word_match']]\n",
    "\n",
    "# input_list = [q_1, q_2]\n",
    "# validation_list = [x_test['question1'].values, x_test['question2'].values]\n",
    "input_list = [q1_train, q2_train]\n",
    "validation_list = [q1_test, q2_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(input_list, y_train,epochs=20, verbose=True, validation_data=(validation_list, y_test), batch_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, accuracy = model.evaluate(input_list, y_train, verbose=False)\n",
    "# print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "# loss, accuracy = model.evaluate(validation_list, y_test, verbose=False)\n",
    "# print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "# plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model.predict([q1_tokenized_test,q2_tokenized_test])\n",
    "# print(predictions[:,0])\n",
    "# sub = pandas.DataFrame({'test_id': test['test_id'], 'is_duplicate': predictions[:,0]})\n",
    "# sub.to_csv('dense_nn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, TimeDistributed, Lambda, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "question_1 = Input(shape=(25,))\n",
    "question_2 = Input(shape=(25,))\n",
    "#word_match = Input(shape=(1,))\n",
    "\n",
    "# Add the word embedding Layer\n",
    "embedding_layer_1 = layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False)(question_1)\n",
    "embedding_layer_1 = layers.SpatialDropout1D(0.3)(embedding_layer_1)\n",
    "\n",
    "embedding_layer_2 = layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False)(question_2)\n",
    "embedding_layer_2 = layers.SpatialDropout1D(0.3)(embedding_layer_2)\n",
    "\n",
    "merged_embedding_vector = keras.layers.concatenate([embedding_layer_1, embedding_layer_2], axis=-1)\n",
    "\n",
    "# Add the LSTM Layer\n",
    "lstm_layer = layers.LSTM(256)\n",
    "\n",
    "encoded_q1 = lstm_layer(embedding_layer_1)\n",
    "encoded_q2 = lstm_layer(embedding_layer_2)\n",
    "\n",
    "merged_embedding_vector = keras.layers.concatenate([encoded_q1, encoded_q2], axis=-1)\n",
    "#merged_vector = keras.layers.concatenate([encoded_q1, encoded_q2], axis=-1)\n",
    "#merged_vector = keras.layers.concatenate([merged_embedding_vector, word_match], axis=-1)\n",
    "\n",
    "# Add the output Layers\n",
    "merged_vector = layers.Dense(100, activation=\"relu\", kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(merged_embedding_vector)\n",
    "merged_vector = BatchNormalization()(merged_vector)\n",
    "merged_vector = layers.Dense(100, activation=\"relu\", kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(merged_vector)\n",
    "merged_vector = BatchNormalization()(merged_vector)\n",
    "#output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "\n",
    "output_layer2 = layers.Dense(1, activation=\"sigmoid\")(merged_vector)\n",
    "\n",
    "# Compile the model\n",
    "model = Model(inputs=[question_1,question_2], outputs=output_layer2)\n",
    "#model = Model(inputs=[question_1,question_2], outputs=output_layer2)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(input_list, y_train,epochs=10, verbose=True, validation_data=(validation_list, y_test), batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(input_list, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(validation_list, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([q1_tokenized_test,q2_tokenized_test])\n",
    "print(predictions[:,0])\n",
    "sub = pandas.DataFrame({'test_id': test['test_id'], 'is_duplicate': predictions[:,0]})\n",
    "sub.to_csv('lstm_nn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
